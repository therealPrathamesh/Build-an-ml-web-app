{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/wlifferth/build-an-ml-web-app/main/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/wlifferth/build-an-ml-web-app/main/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at our most common values in each column\n",
    "for column in train.columns:\n",
    "    print(column)\n",
    "    print(train[column].value_counts().nlargest(5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zipcode looks interesting, but we'll deal with that later\n",
    "# City also could be interesting but we might need to do some extra work with it\n",
    "# Same for state, another categorical variable\n",
    "# Date sold probably isn't helpful, because we know all of these were supposed to have occurred around the same time\n",
    "# bathrooms--finally we're getting into our bread an butter\n",
    "# bedrooms, similar\n",
    "# livingArea also good\n",
    "# HomeType is super intersting, and it's helpful to realize we're only looking at 4 kinds of homes\n",
    "# homeStatus--so this is important, some of these houses haven't actually been sold. We actually want to just filter out the ones that are pending, so we'll do that soon.\n",
    "# Lot area--interesting to see alot of homes dont have any lot--this makes sense for condos and such\n",
    "# LotUnit--this is good to know--some of our areas from above are in square feet, but others are in acres, so we'll need to unify those\n",
    "# address is probably too specific to be helpful to us\n",
    "# and finally price, the thing we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start simply, we know we only want to look at houses that have sold--not ones that are pending. So lets filter on home status:\n",
    "\n",
    "train_only_sold = train[train['homeStatus'] == 'RECENTLY_SOLD'].copy()\n",
    "\n",
    "# then we can actually drop the homeStatus column because we don't need it any more\n",
    "\n",
    "train_only_sold = train_only_sold.drop('homeStatus', axis=1)\n",
    "train_only_sold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also said that we probably don't care about dateSold, but just to be sure, lets look at those values\n",
    "# We can use matplotlib for this!\n",
    "\n",
    "plt.hist(train_only_sold['dateSold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps are pretty weird, but we can tell that most of these came from around the same time, and we're unlikely to get any information from this, so lets just drop it as well\n",
    "train_without_date = train_only_sold.drop('dateSold', axis=1)\n",
    "\n",
    "train_without_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While we're at it, lets drop address too\n",
    "\n",
    "train_without_address = train_without_date.drop('address', axis=1)\n",
    "\n",
    "# It almost fits on one screen!\n",
    "train_without_address.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets also drop id\n",
    "train_without_id = train_without_address.drop('id', axis=1)\n",
    "\n",
    "train_without_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now why don't we graph all our numerical columns!\n",
    "\n",
    "numerical_variables = ['bathrooms', 'bedrooms', 'livingArea', 'lotArea', 'price']\n",
    "\n",
    "\n",
    "for variable in numerical_variables:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(variable)\n",
    "    plt.hist(train_without_id[variable])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of them are super skewed! This is usually an indicator that we have some outliers that are making analysis tricky\n",
    "# There are a lot of ways to deal with outliers, but if you don't have a lot of them, one of the easiest methods is to just get rid of them!\n",
    "\n",
    "# Before we get rid of them, theres some other work we should do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now we have a lotArea column, but we also have a lotUnits column that tells us if the lotArea is in\n",
    "# square feet or acres\n",
    "\n",
    "# There are 43560 square feet in each acre, so if the units is acre, we should multiply the area by 43560\n",
    "\n",
    "def convert_lot_area(row):\n",
    "    if row['lotUnit'] == 'acres':\n",
    "        return row['lotArea'] * 43560\n",
    "    else:\n",
    "        return row['lotArea']\n",
    "\n",
    "train_without_id['lotArea'] = train_without_id.apply(convert_lot_area, axis=1)\n",
    "train_without_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This now looks a lot more normal! Most homes have small yards (or no yards) but a few have bigger yards!\n",
    "plt.hist(train_without_id['lotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! Now we're ready to deal with outliers--if you remember from stats class, an outlier is a value that is more than 3 standard deviations away from the mean\n",
    "\n",
    "distance_from_mean = np.abs(train_without_id['bedrooms'] - train_without_id['bedrooms'].mean())\n",
    "\n",
    "distance_from_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_x_3 = train_without_id['bedrooms'].std() * 3\n",
    "\n",
    "std_x_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms_wihtout_outliers = train_without_id[distance_from_mean < std_x_3]['bedrooms']\n",
    "\n",
    "plt.title('bedrooms with outliers')\n",
    "plt.hist(train_without_id['bedrooms'])\n",
    "plt.show()\n",
    "\n",
    "plt.title('bedrooms without outliers')\n",
    "plt.hist(bedrooms_wihtout_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something is an outlier if it is more than 3 standard deviations away from the mean\n",
    "# And we can get both the mean and standard deviations of our columns really easily!\n",
    "\n",
    "train_no_outliers = train_without_id.copy()\n",
    "\n",
    "train_no_outliers.fillna(train_no_outliers.mean())\n",
    "\n",
    "for variable in numerical_variables:\n",
    "    distance_from_mean = np.abs(train_no_outliers[variable].mean() - train_no_outliers[variable])\n",
    "    train_no_outliers = train_no_outliers[distance_from_mean < (train_no_outliers[variable].std() * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Rows before outlier removal: {len(train_without_id)}')\n",
    "print(f'Rows after outlier removal: {len(train_no_outliers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in numerical_variables:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(variable)\n",
    "    plt.hist(train_no_outliers[variable], bins=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can do something called bivariate analysis--where we see how much two variables interact\n",
    "\n",
    "sns.heatmap(train_no_outliers.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So bathrooms and livingArea seems to be pretty moderately correlated with price, but zipcode  and lotArea are hardly correlated. Can anyone guess why this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we've gotten a sense for our numerical data, but now we need to figure out what we're going to do with our categorical data\n",
    "# State\n",
    "# City\n",
    "# Zip Code\n",
    "# Home Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One strategy we use all the time is called one-hot encoding--this strategy works best if you have a set number of values, like, under 100\n",
    "# This strategy involves turning a single categorical variable with n values, into n binary variables\n",
    "\n",
    "# So instead of \n",
    "\n",
    "colors = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'red', 'green'],\n",
    "})\n",
    "\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get\n",
    "\n",
    "colors_one_hot = pd.DataFrame({\n",
    "    'is_red': [True, False, True, False],\n",
    "    'is_blue': [False, True, True, True],\n",
    "    'is_greem': [False, False, False, True]\n",
    "})\n",
    "\n",
    "colors_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luckily pandas actually gives us a really easy way to do this\n",
    "\n",
    "pd.get_dummies(colors, columns=['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets one-hot encode homeType!\n",
    "\n",
    "train_one_hot = pd.get_dummies(train_no_outliers, columns=['homeType'])\n",
    "\n",
    "train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what about zipcode?\n",
    "# It really has too many values to one-hot encode effectively, and there's a chance we see new zip codes we haven't se before\n",
    "# This is a great chance to think about what zipcode will tell us\n",
    "# Is there some other data related to zip code that would help us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code_df = pd.read_csv('median_income_by_zip_code.csv')\n",
    "\n",
    "zip_code_df['median_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_median_income = pd.merge(train_one_hot, zip_code_df, how='left', left_on='zipcode', right_on='zip_code')\n",
    "\n",
    "train_with_median_income['median_income'].fillna(train_with_median_income['median_income'].mean(), inplace=True)\n",
    "\n",
    "train_with_median_income.drop(['zipcode', 'zip_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
